---
title: "Untitled"
output: html_document
---

### Predicting Country-Level Collaborations in Open Source Software (OSS)

In this file, we outline the process for a regression analysis that aim to predict which factors contribute to country-level collaborations in open source software (OSS). Our original OSS dataset (2008-2019) was scraped from GitHub using the `GHOST.jl` package. We created a summary table of all the users, commits, additions, deletions and collaborations at the country-level in our preprocessing steps and then drew from two additional datasources to add some population and technology variables that might help to predict collaboration tendencies. These data come from the World Bank and World Development Index that include variables related to population estimates, technology adoption, gender/income equity, among others. As we show below, we are not able to use all of these variables due to missingness, but we do develop a strong model from the data we do use. 

#### Importing Packages and Data 

First, we load our packages, the OSS data from the database, and the World Bank data on [population estimates](https://datacatalog.worldbank.org/dataset/population-estimates-and-projections) and [World Development Index data on technology adoption and innovation](https://datacatalog.worldbank.org/dataset/world-development-indicators). 

```{r}

# clear our env and load our packages 
rm(list = ls())
library(tidyverse)
library(readxl)
library(janitor)
library(RPostgreSQL)
library(naniar)
library(mice)
library(caret)
library(VIM)

# next, lets pull in our oss summary data (users, repos, commits, additions, deletions)
# connect to postgresql to get data (in rivanna)
conn <- dbConnect(drv = PostgreSQL(),
                    dbname = "sdad",
                    host = "10.250.124.195",
                    port = 5432,
                    user = Sys.getenv("db_userid"),
                    password = Sys.getenv("db_pwd"))
# query the bipartite edgelist data from github data
ctry_github_activity <- dbGetQuery(conn, str_c("SELECT * FROM gh_sna.desc_intl_ctry_annual_sum"))  
# disconnect from postgresql
dbDisconnect(conn)

# in an earlier file, we ran some country-level network diversity measures (loading them now)
setwd("~/git/oss-2020/data/network-analysis/intl-ctry-nets-cum/wisos-lchn/")
all_diversity_analyses = read_rds("ctry_diversity_cum.rds") %>% 
  rename(country_name = country, net_diversity = diversity) %>% 
  mutate(year = recode(year, `08` = "2008", `0809` = "2009", `0810` = "2010", 
                             `0811` = "2011", `0812` = "2012", `0813` = "2013",
                             `0814` = "2014", `0815` = "2015", `0816` = "2016", 
                             `0817` = "2017", `0818` = "2018", `0819` = "2019"),
         year = as.numeric(year)) %>% 
  distinct(id, country_name, year, net_diversity, 
           louvain_comm, fstgrdy_comm, louvain_range, fstgrdy_range)
all_diversity_analyses

# these are the data that tell us the number of oss collaborations as well as domestic, international and us collab rates 
setwd("~/git/oss-2020/data/intl-indicator-output/")
collaborations_data <- read_csv("oss_all_intl_collaborations_data_2008_2019.csv") %>% 
  rename(country_name = country)
collaborations_data

# join the activity and collaborations data 
ctry_github_joined = ctry_github_activity %>% 
  filter(year > 2007) %>% 
  left_join(collaborations_data, by = c("country_name", "year")) %>% 
  replace(is.na(.), 0)
ctry_github_joined

# pull in the world bank and world development index data
setwd("~/git/oss-2020/data/wdi-data/")
wdi_data = read_csv("WDIData.csv")
dai_data <- read_excel("DAIforweb.xlsx")
population_estimates <- read_csv("Population-EstimatesData.csv")
```

```{r}
# clean the population data 
population_cleaned <- population_estimates %>% 
  clean_names() %>% 
  filter(indicator_name == "Population, total") %>% 
  select(country_name, x2008:x2019) %>% 
  pivot_longer(cols = starts_with("x"), names_to = "year", values_to = "population") %>% 
  # standardize all of the country names
  mutate(year = str_replace(year, "x", ""),
         year = as.numeric(year),
         country_name = str_replace(country_name, " and ", " & ")) %>% 
  mutate(country_name = ifelse(test = str_detect(string = country_name, pattern = "Bahamas, The"), "Bahamas", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Congo, Rep."), "Congo - Brazzaville", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Congo, Dem. Rep."), "Congo - Kinshasa", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Cote d'Ivoire"), "Côte d’Ivoire", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Brunei Darussalam"), "Brunei", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Cabo Verde"), "Cape Verde", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Czech Republic"), "Czechia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Egypt, Arab Rep."), "Egypt", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Gambia, The"), "Gambia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Hong Kong SAR, China"), "Hong Kong SAR China", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Iran, Islamic Rep."), "Iran", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Korea, Dem. People’s Rep."), "North Korea", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Korea, Rep."), "South Korea", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Kyrgyz Republic"), "Kyrgyzstan", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Lao PDR"), "Laos", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Macao SAR, China"), "Macau SAR China", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Macedonia, FYR"), "Macedonia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Micronesia, Fed. Sts."), 
                               "Micronesia (Federated States of)", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Myanmar"), "Myanmar (Burma)", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Russian Federation"), "Russia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Sao Tome & Principe"), "São Tomé & Príncipe", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Sint Maarten (Dutch part)"), "Sint Maarten", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Slovak Republic"), "Slovakia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "St. Vincent & Grenadines"), 
                               "St. Vincent & the Grenadines", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Syrian Arab Republic"), "Syria", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Venezuela, RB"), "Venezuela", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Yemen, Rep."), "Yemen", no = country_name))

# i had to manually select all of the variables i was interested and then validated this list with gizem 
# i created this list and then had to filter out the rest of the data 
filtered_variables = "CPIA trade rating|Trademark applications, resident, by count|Computer, communications and other services|High-technology exports % of manufactured exports|Investment in ICT with private participation|GDP per capita constant 2010 US|CPIA policies for social inclusion/equity cluster average|CPIA gender equality rating|Gini index World Bank estimate|Research and development expenditure % of GDP|Researchers in R&D per million people|Technicians in R&D per million people|Human capital index HCI scale 0-1|Individuals using the Internet % of population|Secure Internet servers per 1 million people"

filtered_df = wdi_data %>% 
  clean_names() %>% 
  select(country_name, country_code, indicator_name, x2008:x2019) %>% 
  mutate(indicator_name = str_replace(indicator_name, "\\(", ""),
         indicator_name = str_replace(indicator_name, "\\)", ""),
         indicator_name = str_replace(indicator_name, "\\$", ""),
         indicator_name = str_replace(indicator_name, "\\(scale 0-1\\)", "scale 0-1")) %>% 
  filter(grepl(filtered_variables, indicator_name))

filtered_df = filtered_df %>% 
  select(country_name, indicator_name, x2008:x2019) %>% 
  pivot_longer(cols = starts_with("x"), names_to = "year", values_to = "count") %>% 
  mutate(year = str_replace(year, "x", ""),
         year = as.numeric(year),
         country_name = str_replace(country_name, " and ", " & ")) %>% 
  # standardize all of the country names
  mutate(country_name = ifelse(test = str_detect(string = country_name, pattern = "Bahamas, The"), "Bahamas", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Congo, Rep."), "Congo - Brazzaville", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Congo, Dem. Rep."), "Congo - Kinshasa", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Cote d'Ivoire"), "Côte d’Ivoire", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Brunei Darussalam"), "Brunei", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Cabo Verde"), "Cape Verde", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Czech Republic"), "Czechia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Egypt, Arab Rep."), "Egypt", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Gambia, The"), "Gambia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Hong Kong SAR, China"), "Hong Kong SAR China", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Iran, Islamic Rep."), "Iran", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Korea, Dem. People’s Rep."), "North Korea", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Korea, Rep."), "South Korea", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Kyrgyz Republic"), "Kyrgyzstan", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Lao PDR"), "Laos", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Macao SAR, China"), "Macau SAR China", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Macedonia, FYR"), "Macedonia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Micronesia, Fed. Sts."), 
                               "Micronesia (Federated States of)", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Myanmar"), "Myanmar (Burma)", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Russian Federation"), "Russia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Sao Tome & Principe"), "São Tomé & Príncipe", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Sint Maarten (Dutch part)"), "Sint Maarten", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Slovak Republic"), "Slovakia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "St. Vincent & Grenadines"), 
                               "St. Vincent & the Grenadines", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Syrian Arab Republic"), "Syria", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Venezuela, RB"), "Venezuela", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Yemen, Rep."), "Yemen", no = country_name)) 

# now, we have to widen the data set and rename the variables to something more practical 
widened_df = filtered_df %>% 
  inner_join(all_diversity_analyses %>% distinct(country_name), by = "country_name") %>%
  mutate(indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Computer, communications and other services % of commercial service exports"), "prc_comp_exports", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Computer, communications and other services % of commercial service imports"), "prc_comp_imports", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "CPIA gender equality rating 1=low to 6=high"), "gender_equality", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "CPIA policies for social inclusion/equity cluster average 1=low to 6=high"), "social_equality", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "CPIA trade rating 1=low to 6=high"), "trade_rating", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "GDP per capita constant 2010 US"), "gdp_per_capita", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Gini index World Bank estimate"), "gini_index", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "High-technology exports % of manufactured exports"), "high_tech_exports", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Human capital index HCI scale 0-1"), "human_capital_index", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Individuals using the Internet % of population"), "prc_internet", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Investment in ICT with private participation current US$"), "ict_investment", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Research and development expenditure % of GDP"), "prc_rnd_expnd", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Researchers in R&D per million people"), "rnd_rchrs_permil", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Technicians in R&D per million people"), "rnd_techs_permil", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Secure Internet servers per 1 million people"), "servers_permil", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Trademark applications, resident, by count"), "trademark_apps", no = indicator_name)) %>%
  pivot_wider(names_from = indicator_name, values_from = count) %>% 
  left_join(all_diversity_analyses, by = c("country_name", "year")) %>% 
  select(country_name, year, net_diversity, louvain_range, fstgrdy_range, everything(), -louvain_comm, -fstgrdy_comm, -id)

# now we have to clean the dai_data 
dai_cleaned = dai_data %>% 
  clean_names() %>% 
  rename(country_name = country) %>% 
  mutate(year = str_replace(year, "x", ""),
         year = as.numeric(year),
         country_name = str_replace(country_name, " and ", " & ")) %>% 
  mutate(country_name = ifelse(test = str_detect(string = country_name, pattern = "Bahamas, The"), "Bahamas", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Congo, Rep."), "Congo - Brazzaville", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Congo, Dem. Rep."), "Congo - Kinshasa", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Cote d'Ivoire"), "Côte d’Ivoire", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Brunei Darussalam"), "Brunei", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Cabo Verde"), "Cape Verde", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Czech Republic"), "Czechia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Egypt, Arab Rep."), "Egypt", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Gambia, The"), "Gambia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Hong Kong SAR, China"), "Hong Kong SAR China", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Iran, Islamic Rep."), "Iran", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Korea, Dem. People’s Rep."), "North Korea", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Korea, Rep."), "South Korea", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Kyrgyz Republic"), "Kyrgyzstan", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Lao PDR"), "Laos", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Macedonia, FYR"), "Macedonia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Macao SAR, China"), "Macau SAR China", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Micronesia, Fed. Sts."), 
                               "Micronesia (Federated States of)", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Myanmar"), "Myanmar (Burma)", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Russian Federation"), "Russia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Sao Tome & Principe"), "São Tomé & Príncipe", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Sint Maarten (Dutch part)"), "Sint Maarten", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Slovak Republic"), "Slovakia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "St. Vincent & Grenadines"), 
                               "St. Vincent & the Grenadines", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Syrian Arab Republic"), "Syria", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Venezuela, RB"), "Venezuela", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Yemen, Rep."), "Yemen", no = country_name)) 

# lets join all of the data together 
widened_with_pop_df = widened_df %>% 
  left_join(population_cleaned, by = c("country_name", "year"))

widened_dai_df = widened_with_pop_df %>% 
  left_join(dai_cleaned, by = c("country_name", "year"))

# and normalize all of the oss data by the population size to get per_capita vars 
wdi_github_joined = ctry_github_joined %>% 
  left_join(widened_dai_df, by = c("country_name", "year")) %>% 
  drop_na(net_diversity) %>% 
  mutate(
    users_per_capita = users / population, 
    repos_per_capita = repos / population, 
    commits_per_capita = commits / population, 
    adds_per_capita = additions / population, 
    dels_per_capita = deletions / population, 
    collabs_per_capita = total_collaborations / population, 
    dom_collabs_per_capita = domestic_collaborations / population,
    us_collabs_per_capita = us_collaborations / population ) %>% 
  select(country_name, year, population, everything()) %>% 
  arrange(year, country_name)

wdi_github_joined
```

#### Checking Missing Data & Limiting the Features  

Let's use the `naniar` package to visualize how much missing data we have out of our ~2500 data points. 

```{r, fig.width=11}
gg_miss_var(wdi_github_joined)
```

Look's like there is a lot of missing data for some variables and a couple more that are just missing certain years in our dataset. We ended up having to remove most of the technology adoption variables, the human capital and equity variables, and only include data from 2009-2018. Still, we end up with around ~1300 data points and 18 features, though we ended up removing some of these features to avoid multicollinearity (see below). 

```{r, fig.width=11}
vis_miss(wdi_github_joined %>% 
           filter(year > 2009 & year < 2018) %>% 
           select(country_name, year, users_per_capita, repos_per_capita, commits_per_capita, adds_per_capita, dels_per_capita, 
                  collabs_per_capita, dom_collabs_per_capita, us_collabs_per_capita, net_diversity, fstgrdy_range,
                  gdp_per_capita, servers_permil, prc_internet, prc_comp_exports, prc_comp_imports #, high_tech_exports
                  #trademark_apps, prc_rnd_expnd, rnd_rchrs_permil, rnd_techs_permil, gini_index, everything(), 
                  #-users:-fstgrdy_range, -starts_with("dai_"), -human_capital_index, -ict_investment, -digital_adoption_index
                  ))
```

```{r}
curated_data <- wdi_github_joined %>% 
           filter(year > 2009 & year < 2018) %>% 
           select(country_name, year, users_per_capita, repos_per_capita, commits_per_capita, adds_per_capita, dels_per_capita, 
                  collabs_per_capita, dom_collabs_per_capita, us_collabs_per_capita, net_diversity, fstgrdy_range,
                  gdp_per_capita, servers_permil, prc_internet, prc_comp_exports, prc_comp_imports)
curated_data
```

Next, we will see how much missing data looks like. The blue and red boxplots should be mostly overlapping, which supports a Missing Completely at Random interpretation. This means we should be able to impute without worrying that something systematic is going on in our data. 

```{r}
pbox(curated_data, pos = 2)
```

#### Transforming Data 

Ok, now let's look at the distributions of the variables. 

```{r}
melted_data <- melt(curated_data)
ggplot(data = melted_data, aes(x = value)) + 
  stat_density() + 
  facet_wrap(~variable, scales = "free")
```

```{r}
chk_data <- curated_data %>% 
  mutate(
    users_per_capita = log(users_per_capita),
    repos_per_capita = log(repos_per_capita),
    commits_per_capita = log(commits_per_capita),
    adds_per_capita = log(adds_per_capita),
    dels_per_capita = log(dels_per_capita),
    collabs_per_capita = log(collabs_per_capita),
    dom_collabs_per_capita = log(dom_collabs_per_capita),
    us_collabs_per_capita = log(us_collabs_per_capita),
    gdp_per_capita = log(gdp_per_capita),
    servers_permil = log(servers_permil),
    fstgrdy_range = log(fstgrdy_range)
  )
melted_data <- melt(chk_data)
ggplot(data = melted_data, aes(x = value)) + 
  stat_density() + 
  facet_wrap(~variable, scales = "free")
```


#### Imputing the missing data 

Next, we are going to impute some of the missing data using the `MICE` package ([van Buuren 2011](https://cran.r-project.org/web/packages/mice/mice.pdf); [see also Alice 2018](https://datascienceplus.com/imputing-missing-data-with-r-mice-package/)). We decided to impute over 5 datasets and to use the predictive mean matching (`pmm`) approach, which ensures that imputed values are plausible by allocating values that are deemed most appropriate based on what a regression line would fit. To do this, we used the `mice()` function, then add it back to the original data with `complete()`, and visualize our now non-missing data. 

```{r, fig.width=11}
tempData <- mice(curated_data, m=5, maxit=50, meth='pmm', seed=500)
summary(tempData)
tempData$imp$prc_internet
completedData <- complete(tempData,1)
vis_miss(completedData)
```

# Now, let's take a look at the correlation matrix of our variables and visualize that as a heatmap. 

```{r}
cor_matrix <- as.data.frame(cor(na.omit(completedData %>% select(-country_name, -year) , method = "pearson")))
cor_matrix <- cor_matrix %>% mutate(across(where(is.numeric), round, 3))
cor_matrix
```

```{r}
melted_cormat <- cor_matrix %>% 
  rownames_to_column("Var1") %>% 
  pivot_longer(!Var1, names_to = "Var2", values_to = "value") 

ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Now, we will fit a linear model. Let's add the number of users, domestic collaborations, and the tech usage and economy variables. 

```{r}
fit1 <- lm(collabs_per_capita ~ year + users_per_capita + commits_per_capita + dom_collabs_per_capita + 
            gdp_per_capita + servers_permil + prc_internet + prc_comp_exports + prc_comp_imports,
          data=completedData)
summary(fit1) # show results
```

That looks pretty good, but I suspect that there is some multicollinearity in here.

```{r}
car::vif(fit)
```

And there is! We will remove those variables and then add in the US collaborations variable alongside the network diversity measures. 

```{r}
fit2 <- lm(collabs_per_capita ~ year + dom_collabs_per_capita + us_collabs_per_capita +  gdp_per_capita + servers_permil + 
             prc_internet + prc_comp_exports + prc_comp_imports + net_diversity + fstgrdy_range,
          data=completedData)
summary(fit2) 
car::vif(fit2)
```

Overall, the model seems to fit pretty well but we should double-check all our assumptions to make sure. 

```{r, fig.width=11}
par(mfrow = c(2, 2))
plot(fit2)
```

```{r}
fit3 <- lm(log(collabs_per_capita) ~ year + dom_collabs_per_capita + us_collabs_per_capita +  gdp_per_capita + servers_permil + 
             prc_internet + prc_comp_exports + prc_comp_imports + net_diversity + fstgrdy_range,
          data=completedData)
summary(fit3) # show results
car::vif(fit3)


```


```{r}
# notes 
# country_name, year, population, all the network measures full there
# gdp_per_capita, servers, prc_internet, prc_computers_imp + exp all less than 15% missing over time 
# looks like HCI is only available for 2017 + 2018 (some have 2010)
# dai and digital adoption is only available for 2014 + 2016 
# gender and social inequality is only available for certain countries 
# prc_rnd_expnd is there for all years (up to 2017/18) for major countries, but lots of missing for random countries 
```

### References 

https://ramorel.github.io/network-range/

https://cran.r-project.org/web/packages/intergraph/vignettes/howto.html

### World Technology Data 

https://datacatalog.worldbank.org/dataset/world-development-indicators

https://www.worldbank.org/en/publication/wdr2016/Digital-Adoption-Index

https://www.nber.org/research/data/historical-cross-country-technology-adoption-hccta-dataset
































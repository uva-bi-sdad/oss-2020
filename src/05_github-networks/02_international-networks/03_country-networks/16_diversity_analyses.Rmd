---
title: "Untitled"
output: html_document
---

```{r}
rm(list = ls())

# thanks to Richard Paquin Morel for this function (https://ramorel.github.io/network-range/) 
netrange <- function(net, attr, directed = TRUE){
  require(reshape2)
  if (class(net) == "igraph") {
      net <- as_adjacency_matrix(net, sparse = F)
    }
  else {
    if(class(net) == "network") {
        net <- as.matrix.network(net)
      }
    else {
        net <- as.matrix(net)
      }
    }
  if(nrow(net) != length(attr)) {
    stop("Number of nodes must match length of attributes vector")
   }
  else {
    if (directed == TRUE){
      ns <- colnames(net)
      el <- melt(net, varnames=c("ego", "alter"), value.name = "weight")
      df <- cbind(rownames(net), attr)
      el$ego_grp <- df[match(el[,1], df[,1]), 2]
      el$alter_grp <- df[match(el[,2], df[,1]), 2]
      
      #FINDING p_k, the strength of ties within each group
      # z_iq = sum of strength of ties from nodes in group _k_ to all other alters
      # z_ij = sum of strength of ties from nodes in group _k_ to alters in group _k_
      
      z_iq <- sapply(unique(attr), function(x) {
        sum(el[which(el$ego_grp==x), "weight"])
      })
      z_ij <- sapply(unique(attr), function(x) {
        sum(el[which(el$ego_grp==x & el$alter_grp==x), "weight"])
      })
      p_k <- z_ij / z_iq
      p_k[is.na(p_k)] <- 0
      
      #FINDING p_ik, the strength of connection from person i to group k
      # x_iq = sum of strength of ties for _i_ to alters in group _k_
      # x_ij = sum of strength of ties for _i_ to all alters
      
      x_ij <- sapply(colnames(net), function(x) {
        sum(el[which(el$ego==x), "weight"])
      }
      )
      x_iq <- list(NULL)
      for(i in colnames(net)) {
        x_iq[[i]] <- sapply(unique(attr), function(x) {
          sum(el[which(el$ego==i & el$alter_grp==x), "weight"])
        }
        )
      }
      x_iq <- x_iq[-c(1)] #x_iq is now a list where each elements is a vector of node _i_ summed strength of tie to group _k_
      
      p_ik <- lapply(1:length(x_iq), 
                     function(x) x_iq[[x]] / x_ij[x])
      
      # FINDING nd_i, the network diversity score for node _i_
      
      nd_i <- sapply(1:length(p_ik), 
                     function(x) 1 - sum(p_k*p_ik[[x]]^2, na.rm = F)
      )
    }
    else {
    ns <- colnames(net)
    el <- melt(net, varnames=c("ego", "alter"), value.name = "weight")
    dup <- data.frame(t(apply(el[,1:2],1,sort)))
    el <- el[!duplicated(dup),]
    df <- cbind(rownames(net), attr)
    el$ego_grp <- df[match(el[,1], df[,1]), 2]
    el$alter_grp <- df[match(el[,2], df[,1]), 2]
    
    #FINDING p_k, the strength of ties within each group
    # z_iq = sum of strength of ties from nodes in group _k_ to all other alters
    # z_ij = sum of strength of ties from nodes in group _k_ to alters in group _k_
    
    z_iq <- sapply(unique(attr), function(x) {
      sum(el[which(el$ego_grp==x | el$alter_grp==x), "weight"])
    })
    z_ij <- sapply(unique(attr), function(x) {
      sum(el[which(el$ego_grp==x & el$alter_grp==x), "weight"])
    })
    p_k <- z_ij / z_iq
    p_k[is.na(p_k)] <- 0
    
    #FINDING p_ik, the strength of connection from person i to group k
    # x_iq = sum of strength of ties for _i_ to alters in group _k_
    # x_ij = sum of strength of ties for _i_ to all alters
    
    x_ij <- sapply(colnames(net), function(x) {
      sum(el[which(el$ego==x | el$alter==x), "weight"])
    }
    )
    x_iq <- list(NULL)
    for(i in colnames(net)) {
      x_iq[[i]] <- sapply(unique(attr), function(x) {
        sum(el[which(el$ego==i & el$alter_grp==x), "weight"],
            el[which(el$alter==i & el$ego_grp==x), "weight"])
      }
      )
    }
    x_iq <- x_iq[-c(1)] #x_iq is now a list where each elements is a vector of node _i_ summed strength of tie to group _k_
    
    p_ik <- lapply(1:length(x_iq), 
                   function(x) x_iq[[x]] / x_ij[x])
    
    
    # FINDING nd_i, the network diversity score for node _i_
    
    nd_i <- sapply(1:length(p_ik), 
                   function(x) 1 - sum(p_k*p_ik[[x]]^2, na.rm = F)
    )
    }
    return(nd_i)
  }
}
```

```{r}
network_diversity_over_time <- function(analysis_year){
  
  # load packages
  for (pkg in c("tidyverse", "igraph", "RPostgreSQL", "lubridate")) {library(pkg, character.only = TRUE)}
  
  # rm(list = ls())
  # analysis_year <- "08"
  
  # connect to postgresql to get data (in rivanna)
  conn <- dbConnect(drv = PostgreSQL(),
                    dbname = "sdad",
                    host = "10.250.124.195",
                    port = 5432,
                    user = Sys.getenv("db_userid"),
                    password = Sys.getenv("db_pwd"))

  # query the bipartite edgelist data from github data
  edgelist <- dbGetQuery(conn, str_c("SELECT country1 AS from, country2 AS to, repo_wts AS weight 
                                     FROM gh_sna.sna_intl_ctry_edgelist_dd_lchn_nbots_", analysis_year, ";"))

  # disconnect from postgresql
  dbDisconnect(conn)

  ################################################################################## convert edgelist to network

  network = igraph::simplify(graph.data.frame(edgelist, directed = FALSE), 
                             remove.multiple = TRUE, remove.loops = FALSE,
                             edge.attr.comb = igraph_opt("edge.attr.comb"))
  is_weighted(network)

  ################################################################################### network diversity measures 

  # construct a nodelist
  nodelist <- data.frame(id = c(1:(igraph::vcount(network))), country = igraph::V(network)$name)
  nodelist$year <- analysis_year
  nodelist$diversity <- igraph::diversity(network)

  detach("package:igraph", unload=TRUE)
  library("statnet")
  library("intergraph")
  
  net_work <- intergraph::asNetwork(network)
  net_work %v% "louvain_comm" <- igraph::cluster_louvain(network)$membership
  net_work %v% "fstgrdy_comm" <- igraph::cluster_fast_greedy(network)$membership
  
  louvain_range <- netrange(net_work, net_work %v% "louvain_comm", directed = TRUE)
  fstgrdy_range <- netrange(net_work, net_work %v% "fstgrdy_comm", directed = TRUE)
  
  net_ranges <- data.frame(country = net_work %v% "vertex.names",
                            louvain_comm = net_work %v% "louvain_comm",
                            fstgrdy_comm = net_work %v% "fstgrdy_comm",
                            louvain_range = louvain_range,
                            fstgrdy_range = fstgrdy_range,
                            stringsAsFactors = F)
  
  nodelist <- nodelist %>% left_join(net_ranges, by = "country")
  
  detach("package:statnet", unload=TRUE)

  # cache the results
  setwd("~/git/oss-2020/data/network-analysis/intl-ctry-nets-cum/wisos-lchn/")
  saveRDS(nodelist, str_c("ctry_diversity_",analysis_year,".rds"))

} # end function

##################################################################################### for loop of all years

for (year in c("08", "0809", "0810", "0811", "0812", "0813", "0814", "0815", "0816", "0817", "0818", "0819")) {
  network_diversity_over_time(year)
}

setwd("~/git/oss-2020/data/network-analysis/intl-ctry-nets-cum/wisos-lchn/")
all_diversity_analyses <- list.files(pattern="ctry_diversity_*") %>% 
  map_df(~read_rds(.))
write_rds(all_diversity_analyses, "ctry_diversity_cum.rds")

```

load data 

```{r}
library(tidyverse)
library(readxl)
library(janitor)

setwd("~/git/oss-2020/data/network-analysis/intl-ctry-nets-cum/wisos-lchn/")
all_diversity_analyses = read_rds("ctry_diversity_cum.rds") %>% 
  rename(country_name = country, net_diversity = diversity) %>% 
  mutate(year = recode(year, `08` = "2008", `0809` = "2009", `0810` = "2010", 
                       `0811` = "2011", `0812` = "2012", `0813` = "2013",
                       `0814` = "2014", `0815` = "2015", `0816` = "2016", 
                       `0817` = "2017", `0818` = "2018", `0819` = "2019"),
         year = as.numeric(year)) %>% 
  distinct(id, country_name, year, net_diversity, louvain_comm, 
           fstgrdy_comm, louvain_range, fstgrdy_range)
all_diversity_analyses

setwd("~/git/oss-2020/data/wdi-data/")
wdi_data = read_csv("WDIData.csv")
dai_data <- read_excel("DAIforweb.xlsx")

filtered_variables = "CPIA trade rating|Trademark applications, resident, by count|Computer, communications and other services|High-technology exports % of manufactured exports|Investment in ICT with private participation|GDP per capita constant 2010 US|CPIA policies for social inclusion/equity cluster average|CPIA gender equality rating|Gini index World Bank estimate|Research and development expenditure % of GDP|Researchers in R&D per million people|Technicians in R&D per million people|Human capital index HCI scale 0-1|Individuals using the Internet % of population|Secure Internet servers per 1 million people"

filtered_df = wdi_data %>% 
  clean_names() %>% 
  select(country_name, country_code, indicator_name, x2008:x2019) %>% 
  mutate(indicator_name = str_replace(indicator_name, "\\(", ""),
         indicator_name = str_replace(indicator_name, "\\)", ""),
         indicator_name = str_replace(indicator_name, "\\$", ""),
         indicator_name = str_replace(indicator_name, "\\(scale 0-1\\)", "scale 0-1")) %>% 
  filter(grepl(filtered_variables, indicator_name))

filtered_df = filtered_df %>% 
  select(country_name, indicator_name, x2008:x2019) %>% 
  pivot_longer(cols = starts_with("x"), names_to = "year", values_to = "count") %>% 
  mutate(year = str_replace(year, "x", ""),
         year = as.numeric(year),
         country_name = str_replace(country_name, " and ", " & ")) %>% 
  mutate(country_name = ifelse(test = str_detect(string = country_name, pattern = "Bahamas, The"), "Bahamas", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Congo, Rep."), "Congo - Brazzaville", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Congo, Dem. Rep."), "Congo - Kinshasa", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Cote d'Ivoire"), "Côte d’Ivoire", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Brunei Darussalam"), "Brunei", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Cabo Verde"), "Cape Verde", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Czech Republic"), "Czechia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Egypt, Arab Rep."), "Egypt", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Gambia, The"), "Gambia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Hong Kong SAR, China"), "Hong Kong SAR China", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Iran, Islamic Rep."), "Iran", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Korea, Dem. People’s Rep."), "North Korea", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Korea, Rep."), "South Korea", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Kyrgyz Republic"), "Kyrgyzstan", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Lao PDR"), "Laos", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Macao SAR, China"), "Macau SAR China", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Micronesia, Fed. Sts."), "Micronesia (Federated States of)", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Myanmar"), "Myanmar (Burma)", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Russian Federation"), "Russia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Sao Tome & Principe"), "São Tomé & Príncipe", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Sint Maarten (Dutch part)"), "Sint Maarten", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Slovak Republic"), "Slovakia", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "St. Vincent & Grenadines"), "St. Vincent & the Grenadines", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Syrian Arab Republic"), "Syria", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Venezuela, RB"), "Venezuela", no = country_name),
         country_name = ifelse(test = str_detect(string = country_name, pattern = "Yemen, Rep."), "Yemen", no = country_name)) 

widened_df = filtered_df %>% 
  inner_join(all_diversity_analyses %>% distinct(country_name), by = "country_name") %>%
  mutate(indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Computer, communications and other services % of commercial service exports"), "prc_comp_exports", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Computer, communications and other services % of commercial service imports"), "prc_comp_imports", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "CPIA gender equality rating 1=low to 6=high"), "gender_equality", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "CPIA policies for social inclusion/equity cluster average 1=low to 6=high"), "social_equality", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "CPIA trade rating 1=low to 6=high"), "trade_rating", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "GDP per capita constant 2010 US"), "gpd_per_capita", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Gini index World Bank estimate"), "gini_index", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "High-technology exports % of manufactured exports"), "high_tech_exports", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Human capital index HCI scale 0-1"), "human_capital_index", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Individuals using the Internet % of population"), "prc_internet", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Investment in ICT with private participation current US$"), "ict_investment", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Research and development expenditure % of GDP"), "prc_rnd_expnd", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Researchers in R&D per million people"), "rnd_rchrs_permil", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Technicians in R&D per million people"), "rnd_techs_permil", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Secure Internet servers per 1 million people"), "servers_permil", no = indicator_name),
         indicator_name = ifelse(test = str_detect(string = indicator_name, 
          pattern = "Trademark applications, resident, by count"), "trademark_apps", no = indicator_name)) %>%
  pivot_wider(names_from = indicator_name, values_from = count) %>% 
  left_join(all_diversity_analyses, by = c("country_name", "year")) %>% 
  select(country_name, year, net_diversity, louvain_range, fstgrdy_range, everything(), -louvain_comm, -fstgrdy_comm, -id)

widened_df
```

```{r}

# connect to postgresql to get data (in rivanna)
  conn <- dbConnect(drv = PostgreSQL(),
                    dbname = "sdad",
                    host = "10.250.124.195",
                    port = 5432,
                    user = Sys.getenv("db_userid"),
                    password = Sys.getenv("db_pwd"))

  # query the bipartite edgelist data from github data
  edgelist <- dbGetQuery(conn, str_c("SELECT * FROM gh.desc_intl_ctry_annual_sum")) # pick up here! 

  # disconnect from postgresql
  dbDisconnect(conn)

```





```{r}
na_removed_df = widened_df %>% drop_na(net_diversity) %>% select(-country_name, -year)
cor(na.omit(na_removed_df), method = "pearson")

```

### References 

https://ramorel.github.io/network-range/

https://cran.r-project.org/web/packages/intergraph/vignettes/howto.html

### World Technology Data 

https://datacatalog.worldbank.org/dataset/world-development-indicators

https://www.worldbank.org/en/publication/wdr2016/Digital-Adoption-Index

https://www.nber.org/research/data/historical-cross-country-technology-adoption-hccta-dataset
































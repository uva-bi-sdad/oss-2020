---
title: "02_name_cleaning"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
# to add 9/14
# province of british columbia
# ufrn.edu.br = Colombian education dept 
# Interpol, United Nations, etc can all have multiple countries attached to organization 
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
rm(list = ls())

for (pkg in c("tidyverse", "igraph", "data.table", "R.utils", "countrycode",
              "RPostgreSQL", "cowplot", "maditr", "gt", "tidytext")) {library(pkg, character.only = TRUE)}

# connect to postgresql to get our data
conn <- dbConnect(drv = PostgreSQL(), 
                  dbname = "sdad", 
                  host = "10.250.124.195",
                  port = 5432, 
                  user = Sys.getenv("db_userid"), 
                  password = Sys.getenv("db_pwd"))

# query the users_gh data (table of all github users) 
us_gov_ffrdcs <- dbGetQuery(conn, "SELECT * FROM us_gov_depts.us_gov_ffrdcs")

# query the users_gh data (table of all github users) 
us_gov_azindex <- dbGetQuery(conn, "SELECT * FROM us_gov_depts.us_gov_azindex_clean")

# query the users_gh data (table of all github users) 
us_gov_manual <- dbGetQuery(conn, "SELECT * FROM us_gov_depts.us_gov_manual")

#github user with emails
gh_extra <- dbGetQuery(conn, "SELECT * FROM gh.ctrs_extra")

# disconnect from postgresql database 
dbDisconnect(conn)

# goverment email domains
#https://home.dotgov.gov/data/ (All .gov domains)
#The official public list of .gov domains is updated about every two weeks:
#List of .gov domains - includes all federal, state, interstate, local, and tribal .gov and .fed.us domains.
email_domain_gov <- read_csv("/sfs/qumulo/qhome/kb7hp/oss-2020/src/sectoring/government/email_domain_federal_full.csv") %>%
  #read_csv("/sfs/qumulo/qhome/zz3hs/oss-data/email_domain_federal_full.csv") %>%
  rename("domain_name" = "Domain Name",
          "domain_type" ="Domain Type") %>%
  select(-"Security Contact Email", 
         -"City", -"State") %>%
  mutate(domain_name = tolower(domain_name), gov = T)

#email domain country
#https://www.sitepoint.com/complete-list-country-code-top-level-domains/
email_domain_cc <- read_csv("/sfs/qumulo/qhome/kb7hp/oss-2020/src/sectoring/government/email_domain_by_country.csv")
#remove dot in the email domain
email_domain_cc$email_domain <- str_replace_all(email_domain_cc$domain, fixed("."), "")
# add in country_code
email_domain_cc$country_code <- countrycode(email_domain_cc$country_name, origin = 'country.name', destination = 'iso2c')

```

First we are going to clean the company code by implementing all of Daniel's techniques 

```{r}
# implementing daniel's approaches 
legal_entities <- read.csv("/sfs/qumulo/qhome/kb7hp/git/dspg20oss/ossPy/keyFiles/curatedLegalEntitesRaw.csv", header=FALSE)
legal_entities <- legal_entities %>% 
  rename(strings = V1) %>% 
  mutate(strings = as.character(strings))
legal_entities$strings <- substring(legal_entities$strings, 2)
legal_entities$strings <- substr(legal_entities$strings,1, nchar(legal_entities$strings)-1)

symbol_strings <- read.csv("/sfs/qumulo/qhome/kb7hp/git/dspg20oss/ossPy/keyFiles/symbolRemove.csv", header=FALSE)
symbol_strings <- symbol_strings %>% 
  rename(strings = V1) %>% 
  mutate(strings = as.character(strings))
symbol_strings$strings <- substring(symbol_strings$strings, 2)
symbol_strings$strings <- substr(symbol_strings$strings,1, nchar(symbol_strings$strings)-1)
symbol_strings <- symbol_strings %>% slice(-17:-20)

curated_domains <- read.csv("/sfs/qumulo/qhome/kb7hp/git/dspg20oss/ossPy/keyFiles/curatedDomains.csv", header=FALSE)
curated_domains <- curated_domains %>% 
  rename(strings = V1) %>% 
  mutate(strings = as.character(strings))
curated_domains$strings <- substring(curated_domains$strings, 2)
curated_domains$strings <- substr(curated_domains$strings,1, nchar(curated_domains$strings)-1)

users_gh <- users_gh %>% 
  mutate(company_original = company) %>%
  mutate(company = str_replace_all(company, paste(c("(?i)(zqx", na.omit(legal_entities$strings), 
                                                    "zqx|, Inc.)"), collapse = "|"), "")) %>% 
  mutate(company = str_replace_all(company, paste(c("(?i)(zqx", na.omit(symbol_strings$strings), 
                                                    ", $|,$|zqx)"), collapse = "|"), "")) %>%
  mutate(company = str_replace_all(company, paste(c("(?i)(zqx", na.omit(curated_domains$strings), 
                                                    "zqx)"), collapse = "|"), "")) %>%
  mutate(company = tolower(company)); users_gh
```


# A count of missingness

```{r eval=FALSE, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
gh_extra_not_na_email <- gh_extra %>%
 filter(!is.na(email))

nrow(gh_extra_not_na_email) 
nrow(gh_extra_not_na_email) /nrow(gh_extra) *100

gh_extra_not_na_company <- gh_extra %>%
 filter(!is.na(company))

nrow(gh_extra_not_na_company) 
nrow(gh_extra_not_na_company) /nrow(gh_extra) *100


gh_extra_not_na <- gh_extra %>%
 filter(!is.na(email) | !is.na(company))
nrow(gh_extra_not_na) 
nrow(gh_extra_not_na) /nrow(gh_extra) *100
```

# Split github user data into users with email and users with no email

```{r}
#match email adress domain
gh_extra <- gh_extra%>%
  as.data.table()%>%#convert to data table
  mutate(email_domain_full =  str_extract(email, "(?<=@).*")) #all strings after @

gh_extra_email <- gh_extra%>%  
  filter(!is.na(email_domain_full))

nrow(gh_extra_email)
nrow(gh_extra_email)/nrow(gh_extra) #27% of github users had email address

##github users don't have emails
gh_extra_no_email <- gh_extra%>%
  filter(is.na(email_domain_full))%>%
  select(login, email, company, cc_multiple) %>% #prepare for a join
  mutate(is.gov = NA)

nrow(gh_extra_no_email)
nrow(gh_extra_no_email)/nrow(gh_extra) #73% do not have emails 
```

# Matching

## Email domain matching

Match email address country domain, gov|fed.us|.mi matching

```{r}
#construct a list of country email domain
email_domain_country_vector <- unlist(email_domain_cc$email_domain)
email_domain_country_pattern <- paste(email_domain_country_vector, collapse="$|")

#format into regex search pattern
email_domain_country_pattern <- paste("\\b(?i)(", email_domain_country_pattern, "$)\\b", sep="")

gh_extra_email <- gh_extra_email %>%
  select(login, email, company, cc_multiple, email_domain_full)%>% # (might add cc_multiple later)
  #first part of the full domain
  mutate(email_domain_first = str_extract(email_domain_full, ".*(?=[.])"))%>% 
  #match goverment email domain (gov, fed.us, mil)
  #note that we are matching any string that contains gov 
  mutate(is_gov_email_domain = if_else(str_detect(email_domain_full, "\\b(?i)(gov|fed.us|.mil)\\b") == T, T, F)) %>% 
  filter(!is.na(email_domain_full))%>%
  #check if the the gh user email domain match the country domain list
  mutate(is.country_email_domain = if_else(str_detect(email_domain_full, email_domain_country_pattern) == T, T, F))%>%
  #extract the country email domain from the full email domain 
  mutate(country_domain = if_else(is.country_email_domain, str_sub(email_domain_full,-2,-1), "NA"))%>%
  #add country name to the dataset by joining with the email domain data
  left_join(email_domain_cc, by = c("country_domain"="email_domain"))%>%
  rename(country_domain_name = country_code)

# get the count
table(gh_extra_email$is_gov_email_domain) 
#726 gh users had .gov (717) or fed.us (only 1), or .mil (only 8) emails

#join the cleaned email from gh with the gov email domain data
gh_extra_email <- gh_extra_email %>%
  left_join(email_domain_gov, by = c("email_domain_full" = "domain_name")) %>%
  mutate(is.usgov = if_else(is.na(domain_type), F, T)) %>%
  dplyr::mutate(gov= replace_na(gov, FALSE))

table(gh_extra_email$gov, gh_extra_email$is_gov_email_domain) 
#430 gh users matched with the email_domain_gov, 296 didn't match (these might be foreign gov)

gh_extra_email <- gh_extra_email %>%
  mutate(is.gov = if_else(is_gov_email_domain == T | gov==T, T, F))%>%
  select(-is_gov_email_domain, -gov)

table(gh_extra_email$is.gov) 
#consistent with the first match, 726 gh users are gov related

#There are 163 unique gov ending emails. 
length(unique(filter(gh_extra_email, is.gov)$email_domain_full))

gh_extra_email%>%
  group_by(is.gov,is.usgov, is.country_email_domain )%>%
  summarize(N=n())

# creating final of matched emails 
gh_extra_email_final <- gh_extra_email%>%
  select(login, email, company, cc_multiple, domain_type, Agency, Organization, is.gov) %>% 
  rename(agency = Agency, organization = Organization)
# this did not 

```

## Full-string matching on identified company names from users previously identified in government sector using email domain
```{r}
gh_extra_company <- rbind(gh_extra_no_email, gh_extra_email_final)
nrow(gh_extra_company)
#company cleaning
gh_extra_company <- gh_extra_company%>%
    mutate(company = tolower(company))
gh_extra_company$company <- str_replace_all(gh_extra_company$company, fixed("u.s."), "united states") 

gh_extra_company$company <- str_replace_all(gh_extra_company$company, "\\b(?i)( us|^us)\\b", "united states")  #note here we have "space us" to avoid catch .us email domain in the company  name. Also note that u.s. pattern can't be identified

#remove all non-alphanumeric characters in the company string
gh_extra_company$company <- str_replace_all(gh_extra_company$company,"[^[:alnum:]]", " ") 

gh_extra_company$c_company <- str_replace_all(gh_extra_company$company, "\\b(?i)(of|and|the|de|for|at|with|from|to|in|on|by|about|as)\\b", "")  

#remove leading space induced by the previous step
gh_extra_company$c_company <- trimws(gh_extra_company$c_company) 

company_confirm_gov <- gh_extra_company%>%
  filter(is.gov)%>%
  group_by(c_company)%>%
  summarize(N=n())%>%
  filter(c_company != "")%>%
  filter(!is.na(c_company))%>%
  arrange(desc(N))%>%
  filter(N > 1) #cutoff threshold: 1

#full string matching
company_confirm_gov_vector <- unlist(company_confirm_gov$c_company)

company_confirm_gov_pattern<-paste(company_confirm_gov_vector, collapse="|")

company_confirm_gov_pattern <- paste("\\b(?i)(", company_confirm_gov_pattern, ")\\b", sep="")

gh_extra_company <- gh_extra_company%>%
  mutate(company_match_gov = if_else(str_detect(c_company, company_confirm_gov_pattern) == T, T, F))%>%
  mutate(company_match_gov= replace_na(company_match_gov, FALSE))

table(filter(gh_extra_company, !is.gov)$company_match_gov)


gh_extra_company <- gh_extra_company%>%
  mutate(is.gov = if_else(company_match_gov==T, T, is.gov))

table(gh_extra_company$is.gov)
```

## Bag of words (singleton/bigrams) matching
```{r}
#companies names listed by previously identified users in government sector
company_list <- gh_extra_company%>%
  filter(is.gov)%>%
  select(c_company)%>%
  filter(!is.na(c_company))

#bigrams
company_list_bigrams <- company_list %>%
  unnest_tokens(bigram, c_company, token = "ngrams", n = 2)%>%
  count(bigram, sort=T) %>%
  filter(n > 1)
company_list_bigrams_vector <- unlist(company_list_bigrams$bigram)

#trigrams
company_list_trigrams <- company_list %>%
  unnest_tokens(trigram, c_company, token = "ngrams", n = 3)%>%
  count(trigram, sort=T)

#quatrigrams
company_list_quatrigrams <- company_list %>%
  unnest_tokens(quatrigram, c_company, token = "ngrams", n = 4)%>%
  count(quatrigram, sort=T)




false_positives <- c("united states", "research center", "home office", "state university", "university chicago", "columbia university", "university manchester", "university washington", "university brookhaven") #note that we don't want to exclude strings that include university since there are useful ones, which induces false negatives. hereby we manually write out false positive ones. 
company_list_bigrams_vector <- setdiff(company_list_bigrams_vector, false_positives)


company_list_bigrams_vector_pattern<-paste(company_list_bigrams_vector, collapse="|")

company_list_bigrams_vector_pattern <- paste("\\b(?i)(", company_list_bigrams_vector_pattern, ")\\b", sep="")

gh_extra_company <- gh_extra_company%>%
  mutate(bigram_match_company = if_else(str_detect(c_company, company_list_bigrams_vector_pattern) == T, T, F))%>%
  mutate(bigram_match_company= replace_na(bigram_match_company, FALSE))
#table(gh_extra_company$bigram_match_company)
table(filter(gh_extra_company, !is.gov)$bigram_match_company)
gh_extra_company <- gh_extra_company%>%
  mutate(is.gov = if_else(bigram_match_company==T, T, is.gov))

table(gh_extra_company$is.gov)

#singletons
bag_of_words <- as.data.frame(unlist(strsplit(company_list$c_company, "\\ ")))
colnames(bag_of_words) <- "company"
bag_of_words <- bag_of_words%>%
  group_by(company)%>%
  summarize(N=n())
```

## U.S. Government Department/Agency name matching
```{r}
#I.azindex
#I.1 agency
az_list_agency <- distinct(us_gov_azindex, agency) %>% 
  rename(institution = agency)%>%
  mutate(dataset = "azindex_agency")

##I.2gov agency
az_list_gov_agency <- distinct(us_gov_azindex, gov_agency) %>%
  rename(institution = gov_agency)%>%
  mutate(dataset = "azindex_gov_agency")

##I.3gov branch
az_list_gov_branch <- distinct(us_gov_azindex, gov_branch)%>%
  rename(institution = gov_branch)%>%
  mutate(dataset = "azindex_gov_branch")%>%
  filter(institution != "None")

##I.4 child agency
az_list_child_agency <- distinct(us_gov_azindex, child_agency)%>%
  rename(institution = child_agency)%>%
  mutate(dataset = "azindex_child_agency")


#II. ffrdc
##II.1 FFRDC
ffrdc_list <- distinct(us_gov_ffrdcs, FFRDC_Name)  %>% 
  rename(institution = FFRDC_Name)%>%
  mutate(dataset = "ffrdc" )

##II.2 agency
ffrdc_list_agency <- us_gov_ffrdcs%>%
  select(Agency, Agency2, Agency3)%>%
  gather("agency_type", "agency_name")%>%
  filter(!is.na(agency_name))%>%
  distinct(agency_name) %>% 
  rename(institution = agency_name)%>%
  mutate(dataset = "ffrdc_agency")

##II.3 sub agency
ffrdc_list_sub_agency <- us_gov_ffrdcs%>%
  select(FFRDC_Name, Sub_Agency, Sub_Agency2, Sub_Agency3)%>%
  gather("agency_type", "agency_name")%>%
  filter(!is.na(agency_name))%>%
  distinct(agency_name)%>% 
  rename(institution = agency_name)%>%
  mutate(dataset = "ffrdc_sub_agency" )

##II.4. 
ffrdc_list_admin <- us_gov_ffrdcs%>%
  select(Admin_Name)%>%
  filter(!is.na(Admin_Name))

ffrdc_list_admin$Admin_Name <- str_replace_all(ffrdc_list_admin$Admin_Name, fixed("Corp."), "Corporation") 

`%notin%` <- Negate(`%in%`)

ffrdc_list_admin <- ffrdc_list_admin %>%
  distinct(Admin_Name) %>% 
  rename(institution = Admin_Name)%>%
  mutate(dataset = "ffrdc_admin")%>%
  filter(institution %notin% c("University of California", "Stanford University", "Princeton University", "Massachusetts Institute of Technology", "Iowa State University", "Carnegie Mellon University", "California Institute of Technology"))

  
#III.usman
usman_list <- us_gov_manual%>%
  distinct( AgencyName)  %>% 
  rename(institution = AgencyName)%>%
  mutate(dataset = "usman")


# bind all lists
all_lists <- rbind(az_list_agency, az_list_gov_agency, az_list_gov_branch, az_list_child_agency, ffrdc_list_agency, ffrdc_list_sub_agency, ffrdc_list_admin, usman_list)
#all_lists <- distinct(all_lists, institution, .keep_all = TRUE) #exclude duplicates


abb_ls <- str_extract_all(all_lists$institution, "\\(.+?\\)")
abb_ls[abb_ls=="character(0)"] <- NA
institution_abb <- unlist(abb_ls)

#extract abbreviation
all_lists_clean <- cbind(all_lists, institution_abb)

all_lists_clean$institution <- sub(" *\\(.*", "", all_lists_clean$institution)

all_lists_clean$institution_abb <- str_replace_all(all_lists_clean$institution_abb , fixed("("), "") 
all_lists_clean$institution_abb <- str_replace_all(all_lists_clean$institution_abb , fixed(")"), "") 
# table(duplicated(all_lists_clean$institution))
# check <- all_lists_clean %>%
#   group_by(institution)%>%
#   summarize(N=n())

abb <- all_lists_clean%>%
  filter(!is.na(institution_abb))%>%
  select(institution, institution_abb)

all_lists_clean_final <- all_lists_clean%>%
  left_join(abb, by = "institution")%>%
  select(-institution_abb.x)%>%
  rename(institution_abb = institution_abb.y)

#write.csv(all_lists_clean_final, file = "us_gov_name_list.csv")

#deduplicate
all_lists_clean <- distinct(all_lists_clean, institution, .keep_all = TRUE) #exclude duplicates

#institution cleaning, the same as gh company name cleaning
all_lists_clean <- all_lists_clean%>%
    mutate(institution = tolower(institution))%>% 
   filter(!is.na(institution))

all_lists_clean$institution <- str_replace_all(all_lists_clean$institution, fixed("u.s."), "united states") 

all_lists_clean$institution <- str_replace_all(all_lists_clean$institution, "\\b(?i)( us|^us)\\b", "united states")  #note here we have "space us" to avoid catch .us email domain in the company  name. Also note that u.s. pattern can't be identified

#remove all non-alphanumeric characters in the company string
all_lists_clean$institution <- str_replace_all(all_lists_clean$institution,"[^[:alnum:]]", " ") 

all_lists_clean$c_institution <- str_replace_all(all_lists_clean$institution, "\\b(?i)(of|and|the|de|for|at|with|from|to|in|on|by|about|as)\\b", "")  

#remove leading space induced by the previous step
all_lists_clean$c_institution <- trimws(all_lists_clean$c_institution) 

all_lists_clean <- all_lists_clean%>%
  mutate(num_alp = str_length(c_institution))%>%
  filter(num_alp >2)   #fix duplicates

all_lists_clean <- distinct(all_lists_clean, c_institution, .keep_all = TRUE) #exclude duplicates


gov_name <- all_lists_clean$c_institution
false_positives <- "mint"

gov_name_vector <- setdiff(gov_name, false_positives)

###Unlist
gov_name_vector <- unlist(all_lists_clean$c_institution)
gov_name_pattern <- paste(gov_name_vector,collapse="|" )
gov_name_pattern <- paste("\\b(?i)(", gov_name_pattern, ")\\b", sep="")

gh_extra_company <- gh_extra_company%>%
  mutate(gov_name_match_company = if_else(str_detect(c_company, gov_name_pattern) == T, T, F))%>%
  mutate(gov_name_match_company= replace_na(gov_name_match_company, FALSE))

nrow(filter(gh_extra_company, !is.gov, gov_name_match_company == T))



gh_extra_company <- gh_extra_company%>%
  mutate(is.gov = if_else(gov_name_match_company==T, T, is.gov))
table(gh_extra_company$is.gov)
```

## Bag of words (singleton/bigrams) matching
```{r}
#companies names listed by previously identified users in government sector
institution_list <- all_lists_clean%>%
  select(c_institution)

#bigrams
institution_list_bigrams <- institution_list %>%
  unnest_tokens(bigram, c_institution, token = "ngrams", n = 2)%>%
  count(bigram, sort=T) %>%
  filter(n > 1)
institution_list_bigrams_vector <- unlist(institution_list_bigrams$bigram)

#trigrams
institution_list_trigrams <- institution_list %>%
  unnest_tokens(trigram, c_institution, token = "ngrams", n = 3)%>%
  count(trigram, sort=T)

#quatrigrams
company_list_quatrigrams <- institution_list %>%
  unnest_tokens(quatrigram, c_institution, token = "ngrams", n = 4)%>%
  count(quatrigram, sort=T)

#todo
#false_positives <- c() 
# institution_list_bigrams_vector <- setdiff(institution_list_bigrams_vector, false_positives)


institution_list_bigrams_vector_pattern<-paste(institution_list_bigrams_vector, collapse="|")

institution_list_bigrams_vector_pattern <- paste("\\b(?i)(", institution_list_bigrams_vector_pattern, ")\\b", sep="")

gh_extra_company <- gh_extra_company%>%
  mutate(institution_bigram_match_company = if_else(str_detect(c_company, institution_list_bigrams_vector_pattern) == T, T, F))%>%
  mutate(institution_bigram_match_company= replace_na(institution_bigram_match_company, FALSE))

#table(gh_extra_company$bigram_match_company)
table(filter(gh_extra_company, !is.gov)$institution_bigram_match_company)
gh_extra_company <- gh_extra_company%>%
  mutate(is.gov = if_else(institution_bigram_match_company==T, T, is.gov))

table(gh_extra_company$is.gov)
```

## Catch the fish--final matching
```{r}
####final step
gh_extra_company <- gh_extra_company%>%
  mutate(is.gov.extra = if_else(str_detect(c_company, "\\b(?i)(gov|government|bureau|federalhomeland security|fbi|cia|census|united state army|usarmy)\\b") == T, T, F))%>%
  mutate(is.gov.extra= replace_na(is.gov.extra, FALSE))

#check <- filter(gh_extra_company, !is.gov, is.gov.extra == T)

nrow(filter(gh_extra_company, !is.gov, is.gov.extra == T))

gh_extra_company <- gh_extra_company%>%
    mutate(is.gov = if_else(is.gov.extra==T, T, is.gov))

table(gh_extra_company$is.gov)
```

# Check internaitonal or domestic
```{r}
# check <- gh_extra_company%>%
#   filter(is.gov)
# table(is.na(check$domain_type))
```


# Prepare for writing to pgAdmin
```{r}
nrow(gh_extra_company)-nrow(gh_extra) #check that we didn't lose any gh users
gh_extra_company_final <- gh_extra_company%>%
  select(login, is.gov)%>%
  mutate(is.gov= replace_na(is.gov, FALSE))%>%
  rename(is_gov = is.gov)%>%
  filter(is_gov)

#table(gh_extra_company_final$is_gov)

# reconnecting to the database 
conn <- dbConnect(drv = PostgreSQL(), 
                  dbname = "sdad", 
                  host = "10.250.124.195", 
                  port = 5432, 
                  user = Sys.getenv("db_userid"), 
                  password = Sys.getenv("db_pwd"))
# writing the new gh_extra_company_final table to postgis_2
dbWriteTable(conn, c("gh", "sna_ctr_gov"), gh_extra_company_final)
# disconnect from postgresql database  
dbDisconnect(conn)
```

